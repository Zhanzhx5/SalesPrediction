import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
import gc
import os
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib import font_manager
warnings.filterwarnings('ignore')

print("ğŸš€ å¼€å§‹é”€é‡åˆ†å¸ƒåˆ†æ...")
print(f"å¼€å§‹æ—¶é—´: {datetime.now()}")

# 1. è¯»å–åŸºç¡€æ•°æ®
print("ğŸ“– è¯»å–åŸºç¡€æ•°æ®...")
# è¯»å–å…¨éƒ¨å•†å“ä¿¡æ¯
goods_df = pd.read_csv('å•†å“ä¿¡æ¯.csv', dtype=str, encoding='utf-8-sig', keep_default_na=False)
store_df = pd.read_csv('åº—é“ºä¿¡æ¯.csv', dtype=str, encoding='utf-8-sig', keep_default_na=False)

goods_df = goods_df.rename(columns={'sgoodsskc': 'item_id'})
store_df = store_df.rename(columns={'sstoreno': 'store_id'})

print(f"å…¨éƒ¨å•†å“ä¿¡æ¯: {len(goods_df)}è¡Œ, åº—é“ºä¿¡æ¯: {len(store_df)}è¡Œ")

# 2. è®¾ç½®å‚æ•°
start_date = pd.to_datetime('2022-01-01')
end_date = pd.to_datetime('2025-06-30')

# ğŸš€ å¤„ç†å…¨éƒ¨åº—é“ºå’Œå…¨éƒ¨å•†å“
all_stores_full = store_df['store_id'].unique()
all_stores = list(all_stores_full)  # å…¨éƒ¨åº—é“º
all_items = goods_df['item_id'].unique()  # å…¨éƒ¨å•†å“

print(f"ğŸ¯ æ•°æ®èŒƒå›´: å¤„ç†å…¨éƒ¨åº—é“ºï¼Œå…±{len(all_stores_full)}ä¸ª")
print(f"ğŸ¯ å•†å“èŒƒå›´: å…¨éƒ¨å•†å“ {len(all_items)}ä¸ª")

# ğŸš€ æ€§èƒ½ä¼˜åŒ–ï¼šé¢„å¤„ç†å•†å“åº—é“ºç‰¹å¾ï¼Œé¿å…é‡å¤merge
print("âš¡ é¢„å¤„ç†å•†å“åº—é“ºç‰¹å¾...")
# è®¾ç½®å•†å“å’Œåº—é“ºIDä¸ºç´¢å¼•ï¼Œæå‡mergeæ•ˆç‡
goods_df = goods_df.set_index('item_id')
store_df = store_df.set_index('store_id')
print("âœ… å•†å“åº—é“ºç‰¹å¾é¢„å¤„ç†å®Œæˆ")

# 3. åˆ†å—è¯»å–é”€å”®æ•°æ®å¹¶è®¡ç®—æ€»é”€é‡
print("ğŸ’¾ åˆ†å—è¯»å–é”€å”®æ•°æ®å¹¶è®¡ç®—æ€»é”€é‡...")
# è®¾ç½®åˆ†å—å¤§å°ï¼ˆæ ¹æ®å†…å­˜æƒ…å†µè°ƒæ•´ï¼‰
CHUNK_SIZE = 1000000  # æ¯æ¬¡è¯»å–100ä¸‡è¡Œ

# åˆå§‹åŒ–æ€»é”€é‡æ•°æ®å­˜å‚¨
total_sales_by_combination = {}

# åˆ†å—è¯»å–é”€å”®æ•°æ®
chunk_count = 0
for chunk in pd.read_csv('é”€å”®ä¿¡æ¯_ç²¾ç®€.csv', 
                        dtype={'dtdate': str, 'sstoreno': str, 'sgoodsskc': str, 'fquantity': str},
                        encoding='utf-8-sig', 
                        keep_default_na=False,
                        chunksize=CHUNK_SIZE):
    
    chunk_count += 1
    print(f"ğŸ“– å¤„ç†ç¬¬ {chunk_count} å—æ•°æ® ({len(chunk):,} è¡Œ)...")
    
    # æ•°æ®æ¸…ç†ï¼ˆå‘é‡åŒ–ï¼‰
    chunk = chunk.rename(columns={'sstoreno': 'store_id', 'sgoodsskc': 'item_id'})
    valid_mask = chunk['dtdate'].str.match(r'^\d{4}-\d{2}-\d{2}$', na=False)
    chunk = chunk[valid_mask]

    chunk['dtdate'] = pd.to_datetime(chunk['dtdate'], errors='coerce')
    chunk['sales'] = pd.to_numeric(chunk['fquantity'], errors='coerce').fillna(0)

    # å°†è´Ÿæ•°çš„é”€é‡æ”¹ä¸º0
    chunk['sales'] = chunk['sales'].clip(lower=0)

    chunk = chunk[(chunk['dtdate'] >= start_date) & (chunk['dtdate'] <= end_date)]
    chunk = chunk.dropna(subset=['dtdate'])

    # ğŸ¯ åªä¿ç•™å…¨éƒ¨åº—é“ºçš„é”€å”®æ•°æ®
    chunk = chunk[chunk['store_id'].isin(all_stores) & chunk['item_id'].isin(all_items)]
    
    if len(chunk) > 0:
        # èšåˆé”€å”®æ•°æ®ï¼ˆæŒ‰åº—é“º-å•†å“ç»„åˆæ±‚å’Œï¼‰
        chunk_agg = chunk.groupby(['store_id', 'item_id'])['sales'].sum().reset_index()
        
        # æ›´æ–°æ€»é”€é‡å­—å…¸
        for _, row in chunk_agg.iterrows():
            key = (row['store_id'], row['item_id'])
            if key in total_sales_by_combination:
                total_sales_by_combination[key] += row['sales']
            else:
                total_sales_by_combination[key] = row['sales']
    
    # æ˜¾ç¤ºè¿›åº¦
    if chunk_count % 5 == 0:
        print(f"   å·²å¤„ç† {chunk_count} å—ï¼Œå½“å‰ç´¯è®¡ç»„åˆæ•°: {len(total_sales_by_combination):,}")

# è½¬æ¢ä¸ºDataFrame
print("ğŸ“Š è½¬æ¢ä¸ºDataFrameå¹¶æ·»åŠ å•†å“åº—é“ºä¿¡æ¯...")
sales_analysis_df = pd.DataFrame([
    {'store_id': store_id, 'item_id': item_id, 'total_sales': sales}
    for (store_id, item_id), sales in total_sales_by_combination.items()
])

print(f"âœ… æ€»é”€é‡è®¡ç®—å®Œæˆï¼Œå…± {len(sales_analysis_df):,} ä¸ªåº—é“º-å•†å“ç»„åˆ")

# æ·»åŠ å•†å“å’Œåº—é“ºä¿¡æ¯
sales_analysis_df = sales_analysis_df.merge(goods_df, left_on='item_id', right_index=True, how='left')
sales_analysis_df = sales_analysis_df.merge(store_df, left_on='store_id', right_index=True, how='left')

# 4. è®¡ç®—é”€é‡åˆ†å¸ƒç»Ÿè®¡
print("ğŸ“ˆ è®¡ç®—é”€é‡åˆ†å¸ƒç»Ÿè®¡...")

# æŒ‰æ€»é”€é‡æ’åº
sales_analysis_df = sales_analysis_df.sort_values('total_sales', ascending=False).reset_index(drop=True)

# è®¡ç®—æ€»é”€é‡
total_sales_sum = sales_analysis_df['total_sales'].sum()
print(f"ğŸ“Š æ€»é”€é‡: {total_sales_sum:,.0f}")

# è®¡ç®—å„ç™¾åˆ†ä½çš„é”€é‡å æ¯”
percentiles = list(range(5, 101, 5))  # 5%, 10%, 15%, ..., 100%
percentile_stats = []

for p in percentiles:
    # è®¡ç®—å‰p%çš„ç»„åˆæ•°é‡
    n_combinations = len(sales_analysis_df)
    top_n = int(n_combinations * p / 100)
    
    if top_n > 0:
        # å‰p%çš„æ€»é”€é‡
        top_sales = sales_analysis_df.head(top_n)['total_sales'].sum()
        # é”€é‡å æ¯”
        sales_percentage = (top_sales / total_sales_sum) * 100
        
        percentile_stats.append({
            'percentile': p,
            'combinations_count': top_n,
            'combinations_percentage': p,
            'sales_sum': top_sales,
            'sales_percentage': sales_percentage
        })

percentile_df = pd.DataFrame(percentile_stats)

# 5. è¾“å‡ºç»Ÿè®¡ç»“æœ
print("=" * 60)
print("ğŸ“Š é”€é‡åˆ†å¸ƒåˆ†æç»“æœ")
print("=" * 60)

print(f"æ€»åº—é“º-å•†å“ç»„åˆæ•°: {len(sales_analysis_df):,}")
print(f"æ€»é”€é‡: {total_sales_sum:,.0f}")
print(f"å¹³å‡æ¯ä¸ªç»„åˆé”€é‡: {total_sales_sum / len(sales_analysis_df):,.2f}")
print(f"ä¸­ä½æ•°é”€é‡: {sales_analysis_df['total_sales'].median():,.2f}")

print("\nğŸ“ˆ å„ç™¾åˆ†ä½é”€é‡å æ¯”:")
print("-" * 80)
print(f"{'ç™¾åˆ†ä½':<8} {'ç»„åˆæ•°':<10} {'ç»„åˆå æ¯”':<10} {'é”€é‡':<15} {'é”€é‡å æ¯”':<10}")
print("-" * 80)

for _, row in percentile_df.iterrows():
    print(f"{row['percentile']:>3}%    {row['combinations_count']:>8,} {row['combinations_percentage']:>8.1f}% "
          f"{row['sales_sum']:>12,.0f} {row['sales_percentage']:>8.1f}%")

# 6. ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
print("\nğŸ¨ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif']=['WenQuanYi Micro Hei']
plt.rcParams['axes.unicode_minus']=False

# åˆ›å»ºå›¾è¡¨
fig, axes = plt.subplots(2, 2, figsize=(16, 12))
fig.suptitle('åº—é“º-å•†å“ç»„åˆé”€é‡åˆ†å¸ƒåˆ†æ', fontsize=16, fontweight='bold')

# 1. é”€é‡å æ¯”æ›²çº¿
ax1 = axes[0, 0]
ax1.plot(percentile_df['percentile'], percentile_df['sales_percentage'], 'b-', linewidth=2, marker='o')
ax1.set_xlabel('ç»„åˆæ’åç™¾åˆ†ä½')
ax1.set_ylabel('ç´¯è®¡é”€é‡å æ¯” (%)')
ax1.set_title('é”€é‡é›†ä¸­åº¦åˆ†æ')
ax1.grid(True, alpha=0.3)
ax1.set_xlim(0, 100)
ax1.set_ylim(0, 100)

# æ·»åŠ å…³é”®ç‚¹æ ‡æ³¨
key_points = [10, 25, 50, 75, 90]
for point in key_points:
    if point in percentile_df['percentile'].values:
        row = percentile_df[percentile_df['percentile'] == point].iloc[0]
        ax1.annotate(f'{row["sales_percentage"]:.1f}%', 
                    xy=(point, row['sales_percentage']), 
                    xytext=(10, 10), textcoords='offset points',
                    bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7),
                    arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))

# 2. é”€é‡åˆ†å¸ƒç›´æ–¹å›¾
ax2 = axes[0, 1]
# ä½¿ç”¨å¯¹æ•°åˆ»åº¦æ˜¾ç¤ºé”€é‡åˆ†å¸ƒ
log_sales = np.log10(sales_analysis_df['total_sales'] + 1)  # +1é¿å…log(0)
ax2.hist(log_sales, bins=50, alpha=0.7, color='skyblue', edgecolor='black')
ax2.set_xlabel('é”€é‡ (log10)')
ax2.set_ylabel('ç»„åˆæ•°é‡')
ax2.set_title('é”€é‡åˆ†å¸ƒç›´æ–¹å›¾')
ax2.grid(True, alpha=0.3)

# 3. å¸•ç´¯æ‰˜å›¾ï¼ˆå‰20%çš„ç»„åˆï¼‰
ax3 = axes[1, 0]
top_20_percent = int(len(sales_analysis_df) * 0.2)
top_20_data = sales_analysis_df.head(top_20_percent)
top_20_data['cumulative_sales'] = top_20_data['total_sales'].cumsum()
top_20_data['cumulative_percentage'] = (top_20_data['cumulative_sales'] / total_sales_sum) * 100

ax3_twin = ax3.twinx()
ax3.bar(range(len(top_20_data)), top_20_data['total_sales'], alpha=0.7, color='lightcoral')
ax3_twin.plot(range(len(top_20_data)), top_20_data['cumulative_percentage'], 'r-', linewidth=2, marker='o')

ax3.set_xlabel('ç»„åˆæ’å')
ax3.set_ylabel('é”€é‡', color='lightcoral')
ax3_twin.set_ylabel('ç´¯è®¡é”€é‡å æ¯” (%)', color='red')
ax3.set_title('å‰20%ç»„åˆçš„å¸•ç´¯æ‰˜åˆ†æ')
ax3.grid(True, alpha=0.3)

# 4. é”€é‡åŒºé—´åˆ†å¸ƒ
ax4 = axes[1, 1]
# å®šä¹‰é”€é‡åŒºé—´
sales_bins = [0, 10, 50, 100, 500, 1000, 5000, 10000, float('inf')]
sales_labels = ['0-10', '11-50', '51-100', '101-500', '501-1K', '1K-5K', '5K-10K', '10K+']
sales_analysis_df['sales_range'] = pd.cut(sales_analysis_df['total_sales'], bins=sales_bins, labels=sales_labels, include_lowest=True)

range_counts = sales_analysis_df['sales_range'].value_counts().sort_index()
ax4.bar(range(len(range_counts)), range_counts.values, alpha=0.7, color='lightgreen')
ax4.set_xlabel('é”€é‡åŒºé—´')
ax4.set_ylabel('ç»„åˆæ•°é‡')
ax4.set_title('é”€é‡åŒºé—´åˆ†å¸ƒ')
ax4.set_xticks(range(len(range_counts)))
ax4.set_xticklabels(range_counts.index, rotation=45)
ax4.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('../sales_distribution_analysis.png', dpi=300, bbox_inches='tight')
print("âœ… å›¾è¡¨å·²ä¿å­˜ä¸º sales_distribution_analysis.png")

# 7. ä¿å­˜è¯¦ç»†ç»Ÿè®¡ç»“æœ
print("ğŸ’¾ ä¿å­˜è¯¦ç»†ç»Ÿè®¡ç»“æœ...")
output_file = '../sales_distribution_stats.csv'
percentile_df.to_csv(output_file, index=False, encoding='utf-8-sig')
print(f"âœ… ç»Ÿè®¡ç»“æœå·²ä¿å­˜ä¸º {output_file}")

# 8. è¾“å‡ºå…³é”®æ´å¯Ÿ
print("\n" + "=" * 60)
print("ğŸ” å…³é”®æ´å¯Ÿ")
print("=" * 60)

# å‰10%çš„é”€é‡å æ¯”
top_10_percent = percentile_df[percentile_df['percentile'] == 10].iloc[0]
print(f"ğŸ“Š å‰10%çš„åº—é“º-å•†å“ç»„åˆè´¡çŒ®äº† {top_10_percent['sales_percentage']:.1f}% çš„æ€»é”€é‡")

# å‰25%çš„é”€é‡å æ¯”
top_25_percent = percentile_df[percentile_df['percentile'] == 25].iloc[0]
print(f"ğŸ“Š å‰25%çš„åº—é“º-å•†å“ç»„åˆè´¡çŒ®äº† {top_25_percent['sales_percentage']:.1f}% çš„æ€»é”€é‡")

# å‰50%çš„é”€é‡å æ¯”
top_50_percent = percentile_df[percentile_df['percentile'] == 50].iloc[0]
print(f"ğŸ“Š å‰50%çš„åº—é“º-å•†å“ç»„åˆè´¡çŒ®äº† {top_50_percent['sales_percentage']:.1f}% çš„æ€»é”€é‡")

# é”€é‡é›†ä¸­åº¦åˆ†æ
print(f"\nğŸ¯ é”€é‡é›†ä¸­åº¦åˆ†æ:")
print(f"   - å‰10%ç»„åˆ: {top_10_percent['sales_percentage']:.1f}% çš„é”€é‡")
print(f"   - å‰25%ç»„åˆ: {top_25_percent['sales_percentage']:.1f}% çš„é”€é‡")
print(f"   - å‰50%ç»„åˆ: {top_50_percent['sales_percentage']:.1f}% çš„é”€é‡")
print(f"   - å50%ç»„åˆ: {100 - top_50_percent['sales_percentage']:.1f}% çš„é”€é‡")

# é•¿å°¾åˆ†æ
bottom_50_percent = percentile_df[percentile_df['percentile'] == 50].iloc[0]
long_tail_percentage = 100 - bottom_50_percent['sales_percentage']
print(f"\nğŸ“ˆ é•¿å°¾æ•ˆåº”åˆ†æ:")
print(f"   - å50%çš„ç»„åˆä»…è´¡çŒ® {long_tail_percentage:.1f}% çš„é”€é‡")
print(f"   - å­˜åœ¨æ˜æ˜¾çš„é•¿å°¾æ•ˆåº”ï¼Œå°‘æ•°ç»„åˆè´¡çŒ®å¤§éƒ¨åˆ†é”€é‡")

# 9. è¾“å‡ºå®Œæˆä¿¡æ¯
print("\n" + "=" * 60)
print("ğŸ‰ é”€é‡åˆ†å¸ƒåˆ†æå®Œæˆ!")
print(f"ç»“æŸæ—¶é—´: {datetime.now()}")
print("=" * 60)
print("è¾“å‡ºæ–‡ä»¶:")
print(f"- ğŸ“Š ç»Ÿè®¡ç»“æœ: {output_file}")
print(f"- ğŸ“ˆ å¯è§†åŒ–å›¾è¡¨: sales_distribution_analysis.png")
print("=" * 60)

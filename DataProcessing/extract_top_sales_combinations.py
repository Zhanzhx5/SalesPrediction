import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
import gc
import os
warnings.filterwarnings('ignore')

print("ğŸš€ å¼€å§‹æå–å‰10%é”€é‡ç»„åˆ...")
print(f"å¼€å§‹æ—¶é—´: {datetime.now()}")

# 1. è¯»å–åŸºç¡€æ•°æ®
print("ğŸ“– è¯»å–åŸºç¡€æ•°æ®...")
# è¯»å–å…¨éƒ¨å•†å“ä¿¡æ¯
goods_df = pd.read_csv('å•†å“ä¿¡æ¯.csv', dtype=str, encoding='utf-8-sig', keep_default_na=False)
store_df = pd.read_csv('åº—é“ºä¿¡æ¯.csv', dtype=str, encoding='utf-8-sig', keep_default_na=False)

goods_df = goods_df.rename(columns={'sgoodsskc': 'item_id'})
store_df = store_df.rename(columns={'sstoreno': 'store_id'})

print(f"å…¨éƒ¨å•†å“ä¿¡æ¯: {len(goods_df)}è¡Œ, åº—é“ºä¿¡æ¯: {len(store_df)}è¡Œ")

# 2. è®¾ç½®å‚æ•°
start_date = pd.to_datetime('2022-01-01')
end_date = pd.to_datetime('2025-06-30')

# ğŸš€ å¤„ç†å…¨éƒ¨åº—é“ºå’Œå…¨éƒ¨å•†å“
all_stores_full = store_df['store_id'].unique()
all_stores = list(all_stores_full)  # å…¨éƒ¨åº—é“º
all_items = goods_df['item_id'].unique()  # å…¨éƒ¨å•†å“

print(f"ğŸ¯ æ•°æ®èŒƒå›´: å¤„ç†å…¨éƒ¨åº—é“ºï¼Œå…±{len(all_stores_full)}ä¸ª")
print(f"ğŸ¯ å•†å“èŒƒå›´: å…¨éƒ¨å•†å“ {len(all_items)}ä¸ª")

# ğŸš€ æ€§èƒ½ä¼˜åŒ–ï¼šé¢„å¤„ç†å•†å“åº—é“ºç‰¹å¾ï¼Œé¿å…é‡å¤merge
print("âš¡ é¢„å¤„ç†å•†å“åº—é“ºç‰¹å¾...")
# è®¾ç½®å•†å“å’Œåº—é“ºIDä¸ºç´¢å¼•ï¼Œæå‡mergeæ•ˆç‡
goods_df = goods_df.set_index('item_id')
store_df = store_df.set_index('store_id')
print("âœ… å•†å“åº—é“ºç‰¹å¾é¢„å¤„ç†å®Œæˆ")

# 3. åˆ†å—è¯»å–é”€å”®æ•°æ®å¹¶è®¡ç®—æ€»é”€é‡
print("ğŸ’¾ åˆ†å—è¯»å–é”€å”®æ•°æ®å¹¶è®¡ç®—æ€»é”€é‡...")
# è®¾ç½®åˆ†å—å¤§å°ï¼ˆæ ¹æ®å†…å­˜æƒ…å†µè°ƒæ•´ï¼‰
CHUNK_SIZE = 1000000  # æ¯æ¬¡è¯»å–100ä¸‡è¡Œ

# åˆå§‹åŒ–æ€»é”€é‡æ•°æ®å­˜å‚¨
total_sales_by_combination = {}

# åˆ†å—è¯»å–é”€å”®æ•°æ®
chunk_count = 0
for chunk in pd.read_csv('é”€å”®ä¿¡æ¯_ç²¾ç®€.csv', 
                        dtype={'dtdate': str, 'sstoreno': str, 'sgoodsskc': str, 'fquantity': str},
                        encoding='utf-8-sig', 
                        keep_default_na=False,
                        chunksize=CHUNK_SIZE):
    
    chunk_count += 1
    print(f"ğŸ“– å¤„ç†ç¬¬ {chunk_count} å—æ•°æ® ({len(chunk):,} è¡Œ)...")
    
    # æ•°æ®æ¸…ç†ï¼ˆå‘é‡åŒ–ï¼‰
    chunk = chunk.rename(columns={'sstoreno': 'store_id', 'sgoodsskc': 'item_id'})
    valid_mask = chunk['dtdate'].str.match(r'^\d{4}-\d{2}-\d{2}$', na=False)
    chunk = chunk[valid_mask]

    chunk['dtdate'] = pd.to_datetime(chunk['dtdate'], errors='coerce')
    chunk['sales'] = pd.to_numeric(chunk['fquantity'], errors='coerce').fillna(0)

    # å°†è´Ÿæ•°çš„é”€é‡æ”¹ä¸º0
    chunk['sales'] = chunk['sales'].clip(lower=0)

    chunk = chunk[(chunk['dtdate'] >= start_date) & (chunk['dtdate'] <= end_date)]
    chunk = chunk.dropna(subset=['dtdate'])

    # ğŸ¯ åªä¿ç•™å…¨éƒ¨åº—é“ºçš„é”€å”®æ•°æ®
    chunk = chunk[chunk['store_id'].isin(all_stores) & chunk['item_id'].isin(all_items)]
    
    if len(chunk) > 0:
        # èšåˆé”€å”®æ•°æ®ï¼ˆæŒ‰åº—é“º-å•†å“ç»„åˆæ±‚å’Œï¼‰
        chunk_agg = chunk.groupby(['store_id', 'item_id'])['sales'].sum().reset_index()
        
        # æ›´æ–°æ€»é”€é‡å­—å…¸
        for _, row in chunk_agg.iterrows():
            key = (row['store_id'], row['item_id'])
            if key in total_sales_by_combination:
                total_sales_by_combination[key] += row['sales']
            else:
                total_sales_by_combination[key] = row['sales']
    
    # æ˜¾ç¤ºè¿›åº¦
    if chunk_count % 5 == 0:
        print(f"   å·²å¤„ç† {chunk_count} å—ï¼Œå½“å‰ç´¯è®¡ç»„åˆæ•°: {len(total_sales_by_combination):,}")

# è½¬æ¢ä¸ºDataFrame
print("ğŸ“Š è½¬æ¢ä¸ºDataFrameå¹¶æ·»åŠ å•†å“åº—é“ºä¿¡æ¯...")
sales_analysis_df = pd.DataFrame([
    {'store_id': store_id, 'item_id': item_id, 'total_sales': sales}
    for (store_id, item_id), sales in total_sales_by_combination.items()
])

print(f"âœ… æ€»é”€é‡è®¡ç®—å®Œæˆï¼Œå…± {len(sales_analysis_df):,} ä¸ªåº—é“º-å•†å“ç»„åˆ")

# æ·»åŠ å•†å“å’Œåº—é“ºä¿¡æ¯
sales_analysis_df = sales_analysis_df.merge(goods_df, left_on='item_id', right_index=True, how='left')
sales_analysis_df = sales_analysis_df.merge(store_df, left_on='store_id', right_index=True, how='left')

# 4. æŒ‰é”€é‡æ’åºå¹¶æå–å‰10%
print("ğŸ“ˆ æŒ‰é”€é‡æ’åºå¹¶æå–å‰10%ç»„åˆ...")

# æŒ‰æ€»é”€é‡æ’åºï¼ˆé™åºï¼‰
sales_analysis_df = sales_analysis_df.sort_values('total_sales', ascending=False).reset_index(drop=True)

# è®¡ç®—å‰10%çš„ç»„åˆæ•°é‡
total_combinations = len(sales_analysis_df)
top_10_percent_count = int(total_combinations * 0.1)

print(f"ğŸ“Š æ€»ç»„åˆæ•°: {total_combinations:,}")
print(f"ğŸ“Š å‰10%ç»„åˆæ•°: {top_10_percent_count:,}")

# æå–å‰10%çš„ç»„åˆ
top_10_percent_df = sales_analysis_df.head(top_10_percent_count).copy()

# æ·»åŠ æ’åä¿¡æ¯
top_10_percent_df['rank'] = range(1, len(top_10_percent_df) + 1)
top_10_percent_df['rank_percentage'] = (top_10_percent_df['rank'] / total_combinations) * 100

# è®¡ç®—ç´¯è®¡é”€é‡å’Œå æ¯”
total_sales_sum = sales_analysis_df['total_sales'].sum()
top_10_percent_df['cumulative_sales'] = top_10_percent_df['total_sales'].cumsum()
top_10_percent_df['sales_percentage'] = (top_10_percent_df['total_sales'] / total_sales_sum) * 100
top_10_percent_df['cumulative_sales_percentage'] = (top_10_percent_df['cumulative_sales'] / total_sales_sum) * 100

# 5. è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
print("=" * 60)
print("ğŸ“Š å‰10%é”€é‡ç»„åˆç»Ÿè®¡")
print("=" * 60)

print(f"æ€»ç»„åˆæ•°: {total_combinations:,}")
print(f"å‰10%ç»„åˆæ•°: {len(top_10_percent_df):,}")
print(f"å‰10%ç»„åˆæ€»é”€é‡: {top_10_percent_df['total_sales'].sum():,.0f}")
print(f"å‰10%ç»„åˆé”€é‡å æ¯”: {(top_10_percent_df['total_sales'].sum() / total_sales_sum) * 100:.2f}%")

print(f"\nå‰10%ç»„åˆé”€é‡ç»Ÿè®¡:")
print(f"  æœ€å¤§é”€é‡: {top_10_percent_df['total_sales'].max():,.0f}")
print(f"  æœ€å°é”€é‡: {top_10_percent_df['total_sales'].min():,.0f}")
print(f"  å¹³å‡é”€é‡: {top_10_percent_df['total_sales'].mean():,.2f}")
print(f"  ä¸­ä½æ•°é”€é‡: {top_10_percent_df['total_sales'].median():,.2f}")

# 6. ä¿å­˜å‰10%ç»„åˆåˆ°CSVæ–‡ä»¶
print("ğŸ’¾ ä¿å­˜å‰10%ç»„åˆåˆ°CSVæ–‡ä»¶...")

# åªä¿ç•™store_idå’Œitem_id
final_df = top_10_percent_df[['store_id', 'item_id']]

# ä¿å­˜æ–‡ä»¶
output_file = '../top_10_percent_sales_combinations.csv'
final_df.to_csv(output_file, index=False, encoding='utf-8-sig')
print(f"âœ… å‰10%ç»„åˆå·²ä¿å­˜ä¸º {output_file}")

# 7. è¾“å‡ºæ–‡ä»¶ä¿¡æ¯
print("\n" + "=" * 60)
print("ğŸ“‹ è¾“å‡ºæ–‡ä»¶ä¿¡æ¯")
print("=" * 60)

print(f"æ–‡ä»¶å: {output_file}")
print(f"è¡Œæ•°: {len(final_df):,}")
print(f"åˆ—æ•°: {len(final_df.columns)}")
print(f"æ–‡ä»¶å¤§å°: {os.path.getsize(output_file) / (1024*1024):.2f} MB")

print(f"\nåˆ—ä¿¡æ¯:")
for i, col in enumerate(final_df.columns, 1):
    print(f"  {i:2d}. {col}")

# 8. è¾“å‡ºå‰10ä¸ªç»„åˆçš„ç¤ºä¾‹
print("\n" + "=" * 60)
print("ğŸ” å‰10ä¸ªç»„åˆç¤ºä¾‹")
print("=" * 60)

print(f"{'æ’å':<4} {'åº—é“ºID':<12} {'å•†å“ID':<12}")
print("-" * 30)

for i, row in enumerate(final_df.head(10).iterrows(), 1):
    print(f"{i:<4} {row[1]['store_id']:<12} {row[1]['item_id']:<12}")

# 9. è¾“å‡ºå®Œæˆä¿¡æ¯
print("\n" + "=" * 60)
print("ğŸ‰ å‰10%é”€é‡ç»„åˆæå–å®Œæˆ!")
print(f"ç»“æŸæ—¶é—´: {datetime.now()}")
print("=" * 60)
print("è¾“å‡ºæ–‡ä»¶:")
print(f"- ğŸ“Š å‰10%ç»„åˆ: {output_file}")
print("=" * 60)
